# service/makeup_service.py
"""
ë©”ì´í¬ì—… ì¶”ë¡  ì„œë¹„ìŠ¤
"""

import os
import sys
import torch
from PIL import Image
from typing import Optional, Union, List

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ pathì— ì¶”ê°€
project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
if project_root not in sys.path:
    sys.path.insert(0, project_root)

from model_manager.makeup_manager import load_model
from libs.spiga_draw import get_draw  # ğŸ”§ libsì—ì„œ import
from facelib import FaceDetector 


# Face Detector ì´ˆê¸°í™” (ê¸€ë¡œë²Œ)
_FACE_DETECTOR = None


def get_face_detector():
    """Face Detector ì‹±ê¸€í†¤"""
    global _FACE_DETECTOR
    if _FACE_DETECTOR is None:
        # ë£¨íŠ¸ì˜ models í´ë” í™•ì¸
        weight_path = "./models/mobilenet0.25_Final.pth"
        if os.path.exists(weight_path):
            _FACE_DETECTOR = FaceDetector(weight_path=weight_path)
        else:
            # ì—†ìœ¼ë©´ ìë™ ë‹¤ìš´ë¡œë“œ
            _FACE_DETECTOR = FaceDetector()
    return _FACE_DETECTOR


def inference(
    id_image: Union[Image.Image, str],
    makeup_image: Union[Image.Image, str],
    guidance_scale: float = 1.6,
    size: int = 512,
    num_inference_steps: int = 30,
    seed: Optional[int] = None,
    device: str = "cuda"
) -> Image.Image:
    """
    ë©”ì´í¬ì—… ì „ì´ ì¶”ë¡ 
    
    Args:
        id_image: ì›ë³¸ ì–¼êµ´ ì´ë¯¸ì§€ (PIL.Image ë˜ëŠ” ê²½ë¡œ)
        makeup_image: ë©”ì´í¬ì—… ì°¸ì¡° ì´ë¯¸ì§€ (PIL.Image ë˜ëŠ” ê²½ë¡œ)
        guidance_scale: ê°€ì´ë˜ìŠ¤ ìŠ¤ì¼€ì¼
        size: ì¶œë ¥ ì´ë¯¸ì§€ í¬ê¸°
        num_inference_steps: ë””ë…¸ì´ì§• ìŠ¤í… ìˆ˜
        seed: ëœë¤ ì‹œë“œ
        device: ì‹¤í–‰ ë””ë°”ì´ìŠ¤
    
    Returns:
        PIL.Image: ë©”ì´í¬ì—… ì „ì´ëœ ê²°ê³¼ ì´ë¯¸ì§€
    """
    # ì´ë¯¸ì§€ ë¡œë“œ
    if isinstance(id_image, str):
        id_image = Image.open(id_image).convert("RGB")
    if isinstance(makeup_image, str):
        makeup_image = Image.open(makeup_image).convert("RGB")
    
    # ë¦¬ì‚¬ì´ì¦ˆ
    id_image = id_image.resize((size, size))
    makeup_image = makeup_image.resize((size, size))
    
    # í¬ì¦ˆ ì´ë¯¸ì§€ ìƒì„±
    detector = get_face_detector()
    pose_image = get_draw(id_image, size=size)
    
    # ëª¨ë¸ ë¡œë“œ (ìºì‹œ ì‚¬ìš©)
    pipeline, makeup_encoder = load_model(device=device)
    
    # ì‹œë“œ ì„¤ì •
    if seed is not None:
        torch.manual_seed(seed)
    
    # ì¶”ë¡  ì‹¤í–‰
    result_img = makeup_encoder.generate(
        id_image=[id_image, pose_image],
        makeup_image=makeup_image,
        pipe=pipeline,
        guidance_scale=guidance_scale,
        num_inference_steps=num_inference_steps,
        seed=seed
    )
    
    return result_img


def batch_inference(
    id_images: List[Union[Image.Image, str]],
    makeup_images: List[Union[Image.Image, str]],
    **kwargs
) -> List[Image.Image]:
    """
    ë°°ì¹˜ ì¶”ë¡ 
    """
    if len(id_images) != len(makeup_images):
        raise ValueError("id_imagesì™€ makeup_imagesì˜ ê¸¸ì´ê°€ ê°™ì•„ì•¼ í•©ë‹ˆë‹¤.")
    
    results = []
    for id_img, makeup_img in zip(id_images, makeup_images):
        result = inference(id_img, makeup_img, **kwargs)
        results.append(result)
    
    return results


def main():
    """ì§ì ‘ ì‹¤í–‰"""
    print("""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘              Stable-Makeup Inference Service                 â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """)
    
    id_input = "./data/test_imgs_makeup/id/ì œë‹ˆ.jpg"
    makeup_ref = "./data/test_imgs_makeup/makeup/ìŠ¤ëª¨í‚¤.jpg"
    output_dir = "./data/output"
    
    if not os.path.exists(id_input):
        print(f"âŒ Source image not found: {id_input}")
        sys.exit(1)
    if not os.path.exists(makeup_ref):
        print(f"âŒ Makeup reference not found: {makeup_ref}")
        sys.exit(1)
    
    os.makedirs(output_dir, exist_ok=True)
    
    id_name = os.path.basename(id_input).split('.')[0]
    makeup_name = os.path.basename(makeup_ref).split('.')[0]
    output_path = os.path.join(output_dir, f"{id_name}_{makeup_name}.png")
    
    try:
        print(f"\n{'='*70}")
        print(f"ğŸ¨ Makeup Transfer")
        print(f"{'='*70}")
        print(f"ğŸ“‚ Source: {id_input}")
        print(f"ğŸ“‚ Makeup: {makeup_ref}")
        print(f"âš™ï¸  Processing...")
        
        result = inference(id_input, makeup_ref, guidance_scale=1.6)
        result.save(output_path)
        
        print(f"âœ… Saved: {output_path}")
        print(f"{'='*70}")
        print("\nğŸ‰ Inference completed successfully!")
        
    except Exception as e:
        print(f"\nâŒ Error: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()