# service/makeup_service.py
"""
ë©”ì´í¬ì—… ì¶”ë¡  ì„œë¹„ìŠ¤ (ì¶”ë¡  ì „ìš©)
- API ë ˆë²¨ì—ì„œ íŒŒì¼ ì €ì¥/ì‘ë‹µ í¬ë§·ì„ ì²˜ë¦¬í•˜ê³ ,
  ì—¬ê¸°ì„œëŠ” ì´ë¯¸ì§€ ì „ì´(inference)ë§Œ ì±…ì„ì§‘ë‹ˆë‹¤.
"""

import os
import sys
import torch
from typing import Optional, Union
from PIL import Image
import numpy as np

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ sys.pathì— ì¶”ê°€
project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
if project_root not in sys.path:
    sys.path.insert(0, project_root)

# ë‚´ë¶€ ëª¨ë“ˆ
from model_manager.makeup_manager import load_model
from libs.spiga_draw import get_draw  # í¬ì¦ˆ/ëœë“œë§ˆí¬ ê¸°ë°˜ draw ì´ë¯¸ì§€
from facelib import FaceDetector  # ì–¼êµ´ ê²€ì¶œê¸° (ëª¨ë¸ ì›œì—…/ë³´ì¡°ìš©)


# ------------------------------------------------------------
# íŒ¨ë”© ìœ í‹¸
# ------------------------------------------------------------
def resize_with_padding(pil_img: Image.Image, target: int = 512, pad_mode: str = "edge") -> Image.Image:
    """
    ì¢…íš¡ë¹„ë¥¼ ìœ ì§€í•´ ê¸´ ë³€ ê¸°ì¤€ìœ¼ë¡œ ë¦¬ì‚¬ì´ì¦ˆí•œ ë’¤, íŒ¨ë”©ì„ ë„£ì–´ ì •ì‚¬ê°(512x512)ìœ¼ë¡œ ë§ì¶˜ë‹¤.
    pad_mode: "edge" | "reflect" | "constant"
    """
    w, h = pil_img.size
    if w == 0 or h == 0:
        raise ValueError("Invalid image size")

    # ì¢…íš¡ë¹„ ìœ ì§€ ë¦¬ì‚¬ì´ì¦ˆ
    if w >= h:
        new_w = target
        new_h = int(round(h * (target / w)))
    else:
        new_h = target
        new_w = int(round(w * (target / h)))

    img_resized = pil_img.resize((new_w, new_h), Image.LANCZOS)

    # Numpyë¡œ íŒ¨ë”©
    arr = np.array(img_resized)
    pad_top = (target - new_h) // 2
    pad_bottom = target - new_h - pad_top
    pad_left = (target - new_w) // 2
    pad_right = target - new_w - pad_left

    if pad_mode == "constant":
        # í°ìƒ‰ íŒ¨ë”©(255)
        arr_padded = np.pad(arr, ((pad_top, pad_bottom), (pad_left, pad_right), (0, 0)), mode="constant", constant_values=255)
    elif pad_mode == "reflect":
        # ë°˜ì‚¬ íŒ¨ë”©
        arr_padded = np.pad(arr, ((pad_top, pad_bottom), (pad_left, pad_right), (0, 0)), mode="reflect")
    else:
        # ê°€ì¥ìë¦¬ ë°˜ë³µ(edge)
        arr_padded = np.pad(arr, ((pad_top, pad_bottom), (pad_left, pad_right), (0, 0)), mode="edge")

    return Image.fromarray(arr_padded)


# ------------------------------------------------------------
# Face Detector (ì˜µì…”ë„, ì›œì—…/ë³´ì¡°)
# ------------------------------------------------------------
_FACE_DETECTOR = None

def get_face_detector():
    """Face Detector ì‹±ê¸€í†¤ (ê°€ì¤‘ì¹˜ê°€ ìˆìœ¼ë©´ ë¡œì»¬ ì‚¬ìš©, ì—†ìœ¼ë©´ ê¸°ë³¸ ìƒì„±)"""
    global _FACE_DETECTOR
    if _FACE_DETECTOR is None:
        weight_path = "./models/mobilenet0.25_Final.pth"
        if os.path.exists(weight_path):
            _FACE_DETECTOR = FaceDetector(weight_path=weight_path)
        else:
            _FACE_DETECTOR = FaceDetector()  # ë‚´ë¶€ì—ì„œ ìë™ ë‹¤ìš´ë¡œë“œ ì‹œë„
    return _FACE_DETECTOR


# ------------------------------------------------------------
# Inference
# ------------------------------------------------------------
def run_inference(
    id_image: Union[Image.Image, str],
    makeup_image: Union[Image.Image, str],
    guidance_scale: float = 1.6,
    size: int = 512,
    num_inference_steps: int = 30,
    seed: Optional[int] = None,
    device: str = "cuda",
) -> Image.Image:
    """
    ë©”ì´í¬ì—… ì „ì´ ì¶”ë¡ .
    Args:
        id_image: ëŒ€ìƒ ì–¼êµ´ ì´ë¯¸ì§€(PIL.Image or ê²½ë¡œ)
        makeup_image: ì°¸ì¡° ë©”ì´í¬ì—… ì´ë¯¸ì§€(PIL.Image or ê²½ë¡œ)
        guidance_scale: CFG scale
        size: ì •ì‚¬ê° ë¦¬ì‚¬ì´ì¦ˆ í¬ê¸°
        num_inference_steps: ë””í“¨ì „ ìŠ¤í… ìˆ˜
        seed: ê³ ì • ì‹œë“œ(ì¬í˜„ì„±)
        device: "cuda" | "cpu"

    Returns:
        PIL.Image: ì „ì´ëœ ê²°ê³¼ ì´ë¯¸ì§€
    """

    # 1) ì´ë¯¸ì§€ ë¡œë“œ/ì „ì²˜ë¦¬
    if isinstance(id_image, str):
        id_image = Image.open(id_image).convert("RGB")
    if isinstance(makeup_image, str):
        makeup_image = Image.open(makeup_image).convert("RGB")

    # 2) 512 ì •ê·œí™” (ì¢…íš¡ë¹„ ìœ ì§€ + íŒ¨ë”©)
    id_image = resize_with_padding(id_image, target=size, pad_mode="edge")
    makeup_image = resize_with_padding(makeup_image, target=size, pad_mode="edge")

    # 3) ì–¼êµ´ ê²€ì¶œê¸° ì›œì—…
    _ = get_face_detector()

    # 4) í¬ì¦ˆ/ëœë“œë§ˆí¬ ê¸°ë°˜ ë³´ì¡° ì´ë¯¸ì§€ ìƒì„±
    pose_image = get_draw(id_image, size=size)

    # 5) ëª¨ë¸ ë¡œë“œ(ìºì‹œ ì‚¬ìš©)
    pipeline, makeup_encoder = load_model(device=device)

    # 6) ì‹œë“œ ê³ ì •(ì„ íƒ)
    if seed is not None:
        torch.manual_seed(seed)

    # 7) ì „ì´ ì‹¤í–‰
    result_img = makeup_encoder.generate(
        id_image=[id_image, pose_image],
        makeup_image=makeup_image,
        pipe=pipeline,
        guidance_scale=guidance_scale,
        num_inference_steps=num_inference_steps,
        seed=seed,
    )

    return result_img


# ------------------------------------------------------------
# CLI í…ŒìŠ¤íŠ¸ìš© (API ê²½ìœ ê°€ ì•„ë‹ˆë¼ ì§ì ‘ ì‹¤í–‰í•  ë•Œë§Œ)
# ------------------------------------------------------------
def main():
    """
    CLI í…ŒìŠ¤íŠ¸:
        python -m service.makeup_service
    """
    print(
        "\n"
        "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n"
        "â•‘              Stable-Makeup Inference Service                 â•‘\n"
        "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n"
    )

    id_input = "./data/test_imgs_makeup/id/ì œë‹ˆ.jpg"
    makeup_ref = "./data/test_imgs_makeup/makeup/ìŠ¤ëª¨í‚¤.jpg"
    output_dir = "./data/output"

    if not os.path.exists(id_input):
        print(f"âŒ Source image not found: {id_input}")
        sys.exit(1)
    if not os.path.exists(makeup_ref):
        print(f"âŒ Makeup reference not found: {makeup_ref}")
        sys.exit(1)

    os.makedirs(output_dir, exist_ok=True)
    id_name = os.path.basename(id_input).split(".")[0]
    makeup_name = os.path.basename(makeup_ref).split(".")[0]
    output_path = os.path.join(output_dir, f"{id_name}_{makeup_name}.png")

    try:
        print("\n" + "=" * 70)
        print("ğŸ¨ Makeup Transfer")
        print("=" * 70)
        print(f"ğŸ“‚ Source: {id_input}")
        print(f"ğŸ“‚ Makeup: {makeup_ref}")
        print("âš™ï¸  Processing...")

        result = run_inference(
            id_image=id_input,
            makeup_image=makeup_ref,
            guidance_scale=1.6,
            size=512,
            num_inference_steps=30,
            seed=None,
            device="cuda" if torch.cuda.is_available() else "cpu",
        )
        result.save(output_path)

        print(f"âœ… Saved: {output_path}")
        print("=" * 70)
        print("\nğŸ‰ Inference completed successfully!\n")

    except Exception as e:
        print(f"\nâŒ Error: {e}")
        import traceback

        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()
