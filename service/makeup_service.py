# service/makeup_service.py
"""
ë©”ì´í¬ì—… ì¶”ë¡  ì„œë¹„ìŠ¤ (ì¶”ë¡  ì „ìš©)
- API ë ˆë²¨ì—ì„œ íŒŒì¼ ì €ì¥/ì‘ë‹µ í¬ë§·ì„ ì²˜ë¦¬í•˜ê³ ,
  ì—¬ê¸°ì„œëŠ” ì´ë¯¸ì§€ ì „ì´(inference)ë§Œ ì±…ì„ì§‘ë‹ˆë‹¤.
"""

import os
import sys
import torch
from typing import Optional, Union
from PIL import Image

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ sys.pathì— ì¶”ê°€
project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
if project_root not in sys.path:
    sys.path.insert(0, project_root)

# ë‚´ë¶€ ëª¨ë“ˆ
from model_manager.makeup_manager import load_model
from libs.spiga_draw import get_draw  # í¬ì¦ˆ/ëœë“œë§ˆí¬ ê¸°ë°˜ draw ì´ë¯¸ì§€
from facelib import FaceDetector  # ì–¼êµ´ ê²€ì¶œê¸° (ëª¨ë¸ ì›œì—…/ë³´ì¡°ìš©)


# ------------------------------------------------------------
# Face Detector (ì˜µì…”ë„, ì›œì—…/ë³´ì¡°)
# ------------------------------------------------------------
_FACE_DETECTOR = None

def get_face_detector():
    """Face Detector ì‹±ê¸€í†¤ (ê°€ì¤‘ì¹˜ê°€ ìˆìœ¼ë©´ ë¡œì»¬ ì‚¬ìš©, ì—†ìœ¼ë©´ ê¸°ë³¸ ìƒì„±)"""
    global _FACE_DETECTOR
    if _FACE_DETECTOR is None:
        weight_path = "./models/mobilenet0.25_Final.pth"
        if os.path.exists(weight_path):
            _FACE_DETECTOR = FaceDetector(weight_path=weight_path)
        else:
            _FACE_DETECTOR = FaceDetector()  # ë‚´ë¶€ì—ì„œ ìë™ ë‹¤ìš´ë¡œë“œ ì‹œë„
    return _FACE_DETECTOR


# ------------------------------------------------------------
# Inference
# ------------------------------------------------------------
def run_inference(
    id_image: Union[Image.Image, str],
    makeup_image: Union[Image.Image, str],
    guidance_scale: float = 1.6,
    size: int = 512,
    num_inference_steps: int = 30,
    seed: Optional[int] = None,
    device: str = "cuda",
) -> Image.Image:
    """
    ë©”ì´í¬ì—… ì „ì´ ì¶”ë¡ .
    Args:
        id_image: ëŒ€ìƒ ì–¼êµ´ ì´ë¯¸ì§€(PIL.Image or ê²½ë¡œ)
        makeup_image: ì°¸ì¡° ë©”ì´í¬ì—… ì´ë¯¸ì§€(PIL.Image or ê²½ë¡œ)
        guidance_scale: CFG scale
        size: ì •ì‚¬ê° ë¦¬ì‚¬ì´ì¦ˆ í¬ê¸°
        num_inference_steps: ë””í“¨ì „ ìŠ¤í… ìˆ˜
        seed: ê³ ì • ì‹œë“œ(ì¬í˜„ì„±)
        device: "cuda" | "cpu"

    Returns:
        PIL.Image: ì „ì´ëœ ê²°ê³¼ ì´ë¯¸ì§€
    """

    # 1) ì´ë¯¸ì§€ ë¡œë“œ/ì „ì²˜ë¦¬
    if isinstance(id_image, str):
        id_image = Image.open(id_image).convert("RGB")
    if isinstance(makeup_image, str):
        makeup_image = Image.open(makeup_image).convert("RGB")

    # ë¦¬ì‚¬ì´ì¦ˆ(ì •ì‚¬ê°)
    id_image = id_image.resize((size, size))
    makeup_image = makeup_image.resize((size, size))

    # 2) (ì„ íƒ) ì–¼êµ´ ê²€ì¶œê¸° ì›œì—…
    #    - ì‹¤ì œ ê²€ì¶œ ê²°ê³¼ë¥¼ ì§ì ‘ ì“°ì§„ ì•Šì§€ë§Œ, ì´ˆê¸°í™” ì§€ì—° ë“±ì„ ë¯¸ë¦¬ ìœ ë°œí•´
    #      ì²« ì¶”ë¡  ë ˆì´í„´ì‹œë¥¼ ì¤„ì´ëŠ” íš¨ê³¼ê°€ ìˆìŒ
    _ = get_face_detector()

    # 3) í¬ì¦ˆ/ëœë“œë§ˆí¬ ê¸°ë°˜ ë³´ì¡° ì´ë¯¸ì§€ ìƒì„±
    pose_image = get_draw(id_image, size=size)

    # 4) ëª¨ë¸ ë¡œë“œ(ìºì‹œ ì‚¬ìš©)
    #    - makeup_manager.load_model() ì•ˆì—ì„œ
    #      UNet/ControlNet/SSR detail_encoder + íŒŒì´í”„ë¼ì¸ êµ¬ì„± ë° ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ
    pipeline, makeup_encoder = load_model(device=device)

    # 5) ì‹œë“œ ê³ ì •(ì„ íƒ)
    if seed is not None:
        torch.manual_seed(seed)

    # 6) ì „ì´ ì‹¤í–‰
    result_img = makeup_encoder.generate(
        id_image=[id_image, pose_image],
        makeup_image=makeup_image,
        pipe=pipeline,
        guidance_scale=guidance_scale,
        num_inference_steps=num_inference_steps,
        seed=seed,
    )

    return result_img


# ------------------------------------------------------------
# CLI í…ŒìŠ¤íŠ¸ìš© (API ê²½ìœ ê°€ ì•„ë‹ˆë¼ ì§ì ‘ ì‹¤í–‰í•  ë•Œë§Œ)
# ------------------------------------------------------------
def main():
    """
    CLI í…ŒìŠ¤íŠ¸:
        python -m service.makeup_service
    """
    print(
        "\n"
        "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n"
        "â•‘              Stable-Makeup Inference Service                 â•‘\n"
        "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n"
    )

    id_input = "./data/test_imgs_makeup/id/ì œë‹ˆ.jpg"
    makeup_ref = "./data/test_imgs_makeup/makeup/ìŠ¤ëª¨í‚¤.jpg"
    output_dir = "./data/output"

    if not os.path.exists(id_input):
        print(f"âŒ Source image not found: {id_input}")
        sys.exit(1)
    if not os.path.exists(makeup_ref):
        print(f"âŒ Makeup reference not found: {makeup_ref}")
        sys.exit(1)

    os.makedirs(output_dir, exist_ok=True)
    id_name = os.path.basename(id_input).split(".")[0]
    makeup_name = os.path.basename(makeup_ref).split(".")[0]
    output_path = os.path.join(output_dir, f"{id_name}_{makeup_name}.png")

    try:
        print("\n" + "=" * 70)
        print("ğŸ¨ Makeup Transfer")
        print("=" * 70)
        print(f"ğŸ“‚ Source: {id_input}")
        print(f"ğŸ“‚ Makeup: {makeup_ref}")
        print("âš™ï¸  Processing...")

        result = run_inference(
            id_image=id_input,
            makeup_image=makeup_ref,
            guidance_scale=1.6,
            size=512,
            num_inference_steps=30,
            seed=None,
            device="cuda" if torch.cuda.is_available() else "cpu",
        )
        result.save(output_path)

        print(f"âœ… Saved: {output_path}")
        print("=" * 70)
        print("\nğŸ‰ Inference completed successfully!\n")

    except Exception as e:
        print(f"\nâŒ Error: {e}")
        import traceback

        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()
