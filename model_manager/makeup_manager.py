# model_manager/makeup_manager.py
"""
ë©”ì´í¬ì—… ëª¨ë¸ ë¡œë”© ë° ìºì‹œ ê´€ë¦¬
"""

import os
import sys
import torch
from typing import Optional, Tuple

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ pathì— ì¶”ê°€
project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
if project_root not in sys.path:
    sys.path.insert(0, project_root)

# libsì—ì„œ import
from libs.pipeline_sd15 import StableDiffusionControlNetPipeline
from diffusers import DDIMScheduler, ControlNetModel
from diffusers import UNet2DConditionModel as OriginalUNet2DConditionModel
from libs.detail_encoder.encoder_plus import detail_encoder

# ê¸€ë¡œë²Œ ìºì‹œ
_CACHED_PIPELINE = None
_CACHED_MAKEUP_ENCODER = None


def load_model(
    model_id: str = "runwayml/stable-diffusion-v1-5",
    checkpoint_path: str = "./checkpoints/makeup",  # ğŸ”§ ë£¨íŠ¸ ê²½ë¡œ
    image_encoder_path: str = "./models/image_encoder_l",  # ğŸ”§ ë£¨íŠ¸ ê²½ë¡œ (ë˜ëŠ” HF)
    device: str = "cuda",
    dtype: torch.dtype = torch.float16,
    force_reload: bool = False
) -> Tuple[object, object]:
    """
    ë©”ì´í¬ì—… ëª¨ë¸ ë¡œë“œ (ìºì‹œ ì‚¬ìš©)
    
    Args:
        model_id: Stable Diffusion ëª¨ë¸ ID
        checkpoint_path: ì²´í¬í¬ì¸íŠ¸ ë””ë ‰í† ë¦¬ ê²½ë¡œ (ê¸°ë³¸: ./checkpoints/makeup)
        image_encoder_path: CLIP ì´ë¯¸ì§€ ì¸ì½”ë” ê²½ë¡œ (ê¸°ë³¸: ./models/image_encoder_l)
        device: ì‹¤í–‰ ë””ë°”ì´ìŠ¤
        dtype: ëª¨ë¸ ë°ì´í„° íƒ€ì…
        force_reload: ê°•ì œ ì¬ë¡œë“œ ì—¬ë¶€
    
    Returns:
        (pipeline, makeup_encoder) íŠœí”Œ
    """
    global _CACHED_PIPELINE, _CACHED_MAKEUP_ENCODER
    
    # ìºì‹œ í™•ì¸
    if not force_reload and _CACHED_PIPELINE is not None and _CACHED_MAKEUP_ENCODER is not None:
        return _CACHED_PIPELINE, _CACHED_MAKEUP_ENCODER
    
    # ì²´í¬í¬ì¸íŠ¸ ê²½ë¡œ ì„¤ì •
    makeup_encoder_path_file = os.path.join(checkpoint_path, "pytorch_model.bin")
    id_encoder_path_file = os.path.join(checkpoint_path, "pytorch_model_1.bin")
    pose_encoder_path_file = os.path.join(checkpoint_path, "pytorch_model_2.bin")
    
    # ì²´í¬í¬ì¸íŠ¸ ì¡´ì¬ í™•ì¸
    required_files = [makeup_encoder_path_file, id_encoder_path_file, pose_encoder_path_file]
    missing_files = [f for f in required_files if not os.path.exists(f)]
    
    if missing_files:
        raise FileNotFoundError(
            f"Required checkpoint files not found in {checkpoint_path}:\n" +
            "\n".join(f"  - {os.path.basename(f)}" for f in missing_files)
        )
    
    # image_encoder_pathê°€ ë¡œì»¬ ê²½ë¡œì¸ì§€ HF ëª¨ë¸ëª…ì¸ì§€ í™•ì¸
    if not os.path.exists(image_encoder_path):
        # HuggingFaceì—ì„œ ë‹¤ìš´ë¡œë“œ (ì˜ˆ: "openai/clip-vit-large-patch14")
        print(f"  Image encoder not found locally, will download from HuggingFace: {image_encoder_path}")
        image_encoder_path = "openai/clip-vit-large-patch14"
    
    # UNet ë¡œë“œ
    unet = OriginalUNet2DConditionModel.from_pretrained(
        model_id, 
        subfolder="unet",
        torch_dtype=dtype
    ).to(device)
    
    # ControlNet ì´ˆê¸°í™”
    id_encoder = ControlNetModel.from_unet(unet)
    pose_encoder = ControlNetModel.from_unet(unet)
    
    # Makeup Encoder ì´ˆê¸°í™”
    makeup_encoder = detail_encoder(
        unet, 
        image_encoder_path, 
        device, 
        dtype=dtype
    )
    
    # ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ
    id_state_dict = torch.load(id_encoder_path_file, map_location="cpu")
    pose_state_dict = torch.load(pose_encoder_path_file, map_location="cpu")
    makeup_state_dict = torch.load(makeup_encoder_path_file, map_location="cpu")
    
    id_encoder.load_state_dict(id_state_dict, strict=False)
    pose_encoder.load_state_dict(pose_state_dict, strict=False)
    makeup_encoder.load_state_dict(makeup_state_dict, strict=False)
    
    # GPUë¡œ ì´ë™
    id_encoder.to(device, dtype=dtype)
    pose_encoder.to(device, dtype=dtype)
    makeup_encoder.to(device, dtype=dtype)
    
    # íŒŒì´í”„ë¼ì¸ ìƒì„±
    pipeline = StableDiffusionControlNetPipeline.from_pretrained(
        model_id,
        safety_checker=None,
        unet=unet,
        controlnet=[id_encoder, pose_encoder],
        torch_dtype=dtype
    ).to(device)
    
    pipeline.scheduler = DDIMScheduler.from_config(pipeline.scheduler.config)
    
    # ìºì‹œ ì €ì¥
    _CACHED_PIPELINE = pipeline
    _CACHED_MAKEUP_ENCODER = makeup_encoder
    
    return pipeline, makeup_encoder


def clear_cache():
    """ìºì‹œëœ ëª¨ë¸ í•´ì œ"""
    global _CACHED_PIPELINE, _CACHED_MAKEUP_ENCODER
    
    _CACHED_PIPELINE = None
    _CACHED_MAKEUP_ENCODER = None
    
    if torch.cuda.is_available():
        torch.cuda.empty_cache()
